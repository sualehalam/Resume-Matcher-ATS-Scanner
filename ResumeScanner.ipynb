{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69d3f64-b03c-4148-9191-e8a7c0912bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9065f-d845-4e98-8b1e-b67e28138234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cc19f-7f0f-4102-844e-93d25e6d4d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a774c05c-5929-4262-91e1-694afe42b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/May/2025 17:32:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2025 17:32:14] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [11/May/2025 17:32:45] \"GET /dashboard HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Removing line breaks from Phone number (510)-392-7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihate\\AppData\\Local\\Temp\\ipykernel_14048\\3349161017.py:162: DeprecationWarning: Parsing dates involving a day of month without a year specified is ambiguious\n",
      "and fails to parse leap day. The default behavior will change in Python 3.15\n",
      "to either always raise an exception or to use a different default year (TBD).\n",
      "To avoid trouble, add a specific year to the input & format.\n",
      "See https://github.com/python/cpython/issues/70647.\n",
      "  start_date = dateparser.parse(f\"{start_month} {start_year}\")\n",
      "C:\\Users\\ihate\\AppData\\Local\\Temp\\ipykernel_14048\\3349161017.py:163: DeprecationWarning: Parsing dates involving a day of month without a year specified is ambiguious\n",
      "and fails to parse leap day. The default behavior will change in Python 3.15\n",
      "to either always raise an exception or to use a different default year (TBD).\n",
      "To avoid trouble, add a specific year to the input & format.\n",
      "See https://github.com/python/cpython/issues/70647.\n",
      "  end_date = dateparser.parse(f\"{end_month} {end_year}\")\n",
      "POST / HTTP/1.1\" 302 -2025 17:34:44] \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARS before globally storing 2.0\n",
      "Match Score based on Resume and Job Description!!! 59.36\n",
      "Intern Boost Applied for Junior\n",
      "Experience_level => Junior\n",
      "MatchScoreBefore boost => 59.36\n",
      "MatchScoreAfter boost => 71.232\n",
      "Matching Score Before -> Skills Match Boosting 71.232\n",
      "[DEBUG] Skill Match Boost: 4 matching skills | New Score: 76.93056\n",
      "BEFORE SAVING TO DB >>>>>>>>>>> sualehalam@gmail.com (510)-392-7033 76.93056 Junior 4\n",
      "BEFORE SAVING TO DB NUMERICAL>> 2.0 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/May/2025 17:34:45] \"GET /resume/111RESUME_Muhammad_Sualeh_Alam.pdf HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARS before globally storing 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/May/2025 17:35:09] \"GET /download/111RESUME_Muhammad_Sualeh_Alam.pdf HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Extracted Skills from Job Description: ['Python', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'Machine Learning', 'Data Science', 'Big-Data', 'Azure', 'Hadoop', 'Data Analytics', 'Statistical Modeling', 'Spark', 'Predictive Analytics']\n",
      "Single Digit Skills !!!  ['AI', 'AWS', 'GCP', 'SQL']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import re\n",
    "import PyPDF2\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import dateparser\n",
    "from flask import redirect, url_for\n",
    "from flask import flash\n",
    "from flask import Response\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from flask import send_file\n",
    "import io\n",
    "from reportlab.lib.utils import simpleSplit\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
    "\n",
    "# Defining Hardcoding skills to extract from the Candidates Profile\n",
    "skill_keywords = [\n",
    "        \"Python\", \"Java\", \"C++\", \"TensorFlow\", \"PyTorch\", \"GraphQL\",\n",
    "        \"Scikit-learn\", \"Machine Learning\", \"Deep Learning\", \"Data Science\", \n",
    "        \"Big Data\", \"Cloud Computing\", \"Azure\", \"MySQL\", \"MATLAB\", \"Hadoop\",\n",
    "        \"Big-Data\", \"Data Analytics\", \"Data Analyst\", \"Predictive Modeling\",\n",
    "        \"Keras\", \"Statistical Modeling\", \"Statistical Analysis\", \n",
    "        # Additional skills\n",
    "        \"Django\", \"Flask\", \"JavaScript\", \"TypeScript\", \"React\", \"Node.js\", \n",
    "        \"Angular\", \"Vue.js\", \"Ruby\", \"C#\", \"Swift\", \"Scala\", \"Kotlin\", \n",
    "        \"Rust\", \"Golang\", \"Insomnia\", \"Postman\", \"Shell Scripting\", \"Bash\",\n",
    "        \"Spark\", \"Kafka\", \"MongoDB\", \"PostgreSQL\", \"Redis\", \"NoSQL\",  \n",
    "        \"Docker\", \"Kubernetes\", \"CI/CD\", \"GitHub\", \"GitLab\", \"Jenkins\", \n",
    "        \"Terraform\", \"Ansible\", \"Puppet\", \"Selenium\", \"Network Security\",\n",
    "        \"DevOps\", \"Agile\", \"Scrum\", \"Test Automation\", \"Unit Testing\",  \n",
    "        \"Pandas\", \"NumPy\", \"Matplotlib\", \"Seaborn\", \"OpenCV\", \"Computer Vision\", \n",
    "        \"Reinforcement Learning\", \"Data Engineering\", \"Data Warehousing\", \n",
    "        \"Tableau\", \"Power BI\", \"Business Intelligence\", \"Data Pipeline\",\n",
    "        \"Graph Databases\", \"Elasticsearch\", \"Quantum Computing\", \"JIRA\",\n",
    "        \"Blockchain\", \"Cryptocurrency\", \"Smart Contracts\", \"Microservice\", \n",
    "        \"API Development\", \"OAuth\", \"Web Services\", \"RESTful APIs\", \n",
    "        \"Web Scraping\", \"Web Development\", \"Mobile Development\", \"Android\", \n",
    "        \"Flutter\", \"Xamarin\", \"Networking\", \"Cybersecurity\", \"Large Language Model\",\n",
    "        \"Penetration Testing\", \"Intrusion Detection\", \"Cloud Security\", \"DevSecOps\",\n",
    "\n",
    "        # Adding more skills\n",
    "        \"Alteryx\", \"Data Mining\", \"DevSecOps\", \"Data Visualization\", \"Data Visualisation\",\n",
    "        \"Microsoft Office\", \"Powerpoint\", \".NET\", \"Dotnet\", \"MXNet\", \"Apache\"\n",
    "        \"Feature Engineering\", \"Data Exploration\", \"Prescriptive Analytics\",\n",
    "        \"Predictive Analytics\", \"Predictive Models Analysis\", \"Forecast\", \"Data Mining\",\n",
    "        \"Quantitative analysis\", \"Assembly\", \"Perl\", \"Assembly\", \"Qlik Sense\", \"Qlik Sense\",\n",
    "        \"Snowflake\", \"Neural Network\", \"GANs\", \"LangChain\", \"MLflow\", \"Hugging Face\",\n",
    "        \"AutoML\", \"XGBoost\", \"LightGBM\", \"CatBoost\", \"Grafana\",\n",
    "\n",
    "        # Cyber Security Skills\n",
    "        \"Burp Suite\", \"Kali Linux\", \"Nmap\", \"Wireshark\", \"Packet Tracer\", \"Splunk\",\n",
    "        \"Metasploit\", \"Prometheus\",\n",
    "\n",
    "        # Testing / QA\n",
    "        \"TestNG\", \"JUnit\", \"Cypress\",\n",
    "\n",
    "        # Mobile Development\n",
    "        \"React Native\", \"SwiftUI\", \"Ionic\",  \n",
    "    ]\n",
    "\n",
    "# Defining Single Digit Skills\n",
    "singledigit_skills = [\"AI\", \"R\", \"C\", \"AWS\", \"LLM\", \"GO\", \"NLP\", \"ETL\",\n",
    "                      \"GCP\", \"HTML\", \"CSS\", \"PHP\", \"SQL\", \"ELK\", \"JWT\",\n",
    "                      \"SPSS\", \"SOAP\", \"JAX\", \"IAM\",\n",
    "                      \"Go\", \"Aws\", \"Visio\", \"Excel\", \"Vuex\"                     # Differently written single word skills\n",
    "                     ]\n",
    "\n",
    "# Global Variable\n",
    "job_descriptionGlobal = \"\"\n",
    "resume_YearsExperience = 0\n",
    "\n",
    "def extract_text(filepath):\n",
    "    text = \"\"\n",
    "    if filepath.lower().endswith(\".pdf\"):\n",
    "        try:\n",
    "            with open(filepath, \"rb\") as pdf_file:\n",
    "                reader = PyPDF2.PdfReader(pdf_file)\n",
    "                for page in reader.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF file: {e}\", file=sys.stderr)\n",
    "    elif filepath.lower().endswith(\".docx\"):\n",
    "        try:\n",
    "            import mammoth\n",
    "            with open(filepath, \"rb\") as docx_file:\n",
    "                result = mammoth.extract_raw_text(docx_file)\n",
    "                text = result.value if result else \"\"\n",
    "        except ImportError:\n",
    "            print(\"Mammoth module not found. Cannot parse DOCX files.\", file=sys.stderr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading DOCX file: {e}\", file=sys.stderr)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_email(text):\n",
    "    match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6}\", text)\n",
    "    return match.group(0) if match else \"Email not found\"\n",
    "\n",
    "# Works for Ashish also and others but with a line break with ashish\n",
    "def extract_phone(text):\n",
    "    # Update regex to handle possible line breaks and other delimiters\n",
    "    match = re.search(r\"(?:\\+\\d{1,3}\\s?)?(?:\\(?\\d{2,4}\\)?[\\s.-]*)(\\d{2,4})[\\s.-]*(\\d{2,4})[\\s.-]*(\\d{2,4})\", text)\n",
    "    return match.group(0) if match else \"Phone not found\"\n",
    "\n",
    "def normalize_skill(skill):\n",
    "    return skill.replace(\"-\", \"\").replace(\" \", \"\").lower()     #Normalize a skill by removing hyphens, spaces, and converting to lowercase.\n",
    "\n",
    "# Match skills even if not capitalized, ignore hyphens, spaces, etc\n",
    "def extract_skills(text):\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Create a mapping of normalized skills to original skill names\n",
    "    normalized_skill_map = {normalize_skill(skill): skill for skill in skill_keywords}\n",
    "    \n",
    "    # Find matches in text\n",
    "    extracted_skills = [\n",
    "        normalized_skill_map[norm_skill]\n",
    "        for norm_skill in normalized_skill_map\n",
    "        if norm_skill in normalize_skill(text_lower)\n",
    "    ]\n",
    "\n",
    "    return extracted_skills if extracted_skills else [\"No Skills Found\"]\n",
    "\n",
    "# Removing duplicate skills from the list\n",
    "def deduplicate_skills(skills):\n",
    "    seen = {}\n",
    "    for skill in skills:\n",
    "        key = skill.lower()\n",
    "        # Prefer capitalized skill if seen before in lowercase\n",
    "        if key not in seen or skill[0].isupper():\n",
    "            seen[key] = skill\n",
    "    return list(seen.values())\n",
    "\n",
    "# new function handles experience parsing without \"-\" new REGEX (Extract Years from Resume)\n",
    "def categorize_experience(text):\n",
    "    global resume_YearsExperience  # Ensure we use the latest stored resume_YearsExperience\n",
    "    \n",
    "    match = re.search(r\"(?:(?:over|more than|at least|up to)\\s*)?(\\d{1,2})\\s*(?:\\+\\s*)?years?\", text.lower())\n",
    "    if match:\n",
    "        years = int(match.group(1))\n",
    "    else:\n",
    "        # Updated regex: supports \"Aug 2022 - Aug 2023\" and \"Jun 2024 Aug 2024\"\n",
    "        date_match = re.findall(\n",
    "            r\"(\\w{3,9})\\s+(\\d{4})\\s*(?:[-–]\\s*|(?=\\w{3,9}\\s+\\d{4}))(\\w{3,9})\\s+(\\d{4})\", text\n",
    "        )\n",
    "        years = 0\n",
    "        if date_match:\n",
    "            for start_month, start_year, end_month, end_year in date_match:\n",
    "                try:\n",
    "                    start_date = dateparser.parse(f\"{start_month} {start_year}\")\n",
    "                    end_date = dateparser.parse(f\"{end_month} {end_year}\")\n",
    "                    if start_date and end_date:\n",
    "                        duration = (end_date.year - start_date.year) + (end_date.month - start_date.month) / 12\n",
    "                        years += max(0, duration)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    resume_YearsExperience = years            # Globally storing number of experience years\n",
    "    print('YEARS before globally storing', years)\n",
    "    \n",
    "    if years >= 7:\n",
    "        return \"Senior\"\n",
    "    elif years >= 3 and years <=7:\n",
    "        return \"Mid-Level\"\n",
    "    elif years > 0:\n",
    "        return \"Junior\"\n",
    "    return \"Not Mentioned\"\n",
    "\n",
    "# Extracting experience years from the job_description\n",
    "def get_required_experience(job_description):\n",
    "    \"\"\"Extracts required experience level from job description text.\"\"\"\n",
    "    if not job_description:\n",
    "        return \"Not Mentioned\"\n",
    "\n",
    "    job_description = job_description.lower()\n",
    "\n",
    "    if \"intern\" in job_description or \"pursuing\" in job_description:\n",
    "        return \"Intern\"\n",
    "    elif any(term in job_description for term in [\"entry-level\", \"0-2 years\", \"junior\"]):\n",
    "        return \"Junior\"\n",
    "    elif any(term in job_description for term in [\"3-7 years\", \"mid-level\"]):\n",
    "        return \"Mid-Level\"\n",
    "    elif any(term in job_description for term in [\"7+ years\", \"senior\"]):\n",
    "        return \"Senior\"\n",
    "\n",
    "    return \"Not Mentioned\"\n",
    "\n",
    "\n",
    "def adjust_match_score(match_score, experience_level, job_description, resume_skills):\n",
    "    required_experience = get_required_experience(job_description)\n",
    "    job_skills = extract_skills_from_job(job_description)\n",
    "    single_skills = match_single_digit_skills(job_description, singledigit_skills)\n",
    "    job_skills = job_skills + single_skills                             # Combine both skills into single list\n",
    "\n",
    "    experience_mapping = {\n",
    "        \"Intern\": [\"Intern\"],\n",
    "        \"Junior\": [\"Entry-Level\", \"0-2 years\", \"Junior\"],\n",
    "        \"Mid-Level\": [\"Mid-Level\", \"3-7 years\"],\n",
    "        \"Senior\": [\"Senior\", \"7+ years\"]\n",
    "    }\n",
    "\n",
    "    job_description_lower = job_description.lower()\n",
    "    \n",
    "    # Experience Level Boost (20%)\n",
    "    \n",
    "    # job_description (if Internship job matched with a junior, senior, mid-level employee boosted)\n",
    "    if any(term in job_description_lower for term in [\"intern\", \"internship\", \"interns\", \"entry-level\"]):\n",
    "        if experience_level in [\"Intern\", \"Junior\", \"Mid-Level\", \"Senior\"]:\n",
    "            print(f\"Intern Boost Applied for {experience_level}\")\n",
    "            print(\"Experience_level =>\", experience_level)\n",
    "            print(\"MatchScoreBefore boost =>\", match_score)\n",
    "            match_score = min(100, match_score * 1.20)  # Boost score by 20%\n",
    "            print(\"MatchScoreAfter boost =>\", match_score)\n",
    "    # Matched with Junior position\n",
    "    elif any(term in job_description_lower for term in [\"entry-level\", \"entry level\", \"0-2 year\"]):\n",
    "        if experience_level in [\"Junior\", \"Senior\", \"Mid-Level\"]:\n",
    "            print(f\"Junior Match Applied for {experience_level}\")\n",
    "            print(\"Experience_level =>\", experience_level)\n",
    "            print(\"MatchScoreBefore boost =>\", match_score)\n",
    "            match_score = min(100, match_score * 1.20)  # Boost score by 20%\n",
    "    # Matched with Mid-Level position\n",
    "    elif any(term in job_description_lower for term in [\"mid-level\", \"mid level\", \"3-7 year\"]):\n",
    "        if experience_level in [\"Senior\", \"Mid-Level\"]:\n",
    "            print(f\"MidLevel Match Applied for {experience_level}\")\n",
    "            print(\"Experience_level =>\", experience_level)\n",
    "            print(\"MatchScoreBefore boost =>\", match_score)\n",
    "            match_score = min(100, match_score * 1.20)  # Boost score by 20%\n",
    "    # Matched with Senior position\n",
    "    elif any(term in job_description_lower for term in [\"senior\", \"7+ year\"]):\n",
    "        if experience_level in [\"Senior\", \"senior\"]:\n",
    "            print(f\"Senior Match Applied for {experience_level}\")\n",
    "            print(\"Experience_level =>\", experience_level)\n",
    "            print(\"MatchScoreBefore boost =>\", match_score)\n",
    "            match_score = min(100, match_score * 1.20)  # Boost score by 20%\n",
    "            \n",
    "    \n",
    "    # Skills Match Boost (Up to 20%)\n",
    "    skill_overlap = len(set(resume_skills) & set(job_skills))\n",
    "    if skill_overlap > 0:\n",
    "        skill_boost = min(100, match_score * (1 + (0.02 * skill_overlap)))  # 2% boost per matching skill\n",
    "        print('Matching Score Before -> Skills Match Boosting', match_score)\n",
    "        print(f\"[DEBUG] Skill Match Boost: {skill_overlap} matching skills | New Score: {skill_boost}\")\n",
    "        match_score = skill_boost\n",
    "    \n",
    "    return min(100, match_score), skill_overlap\n",
    "\n",
    "\n",
    "def save_to_db(name, email, phone, skills, score, experience_level, experience_years=0.0, num_skills_matched=0):    \n",
    "# def save_to_db(name, email, phone, skills, score, experience_level):\n",
    "    try:\n",
    "        conn = sqlite3.connect(\"resumes.db\", check_same_thread=False)\n",
    "        cursor = conn.cursor()\n",
    "       \n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS resumes (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT, email TEXT, phone TEXT, skills TEXT, score REAL, experience_level TEXT, report TEXT,\n",
    "                experience_years REAL, skills_matched INTEGER                     \n",
    "            )\n",
    "        \"\"\")        \n",
    "\n",
    "        # ✅ Generate the formatted report text\n",
    "        report = f\"\"\"\n",
    "        Resume ATS Analysis Report\n",
    "\n",
    "        Filename: {name}\n",
    "        Email: {email}\n",
    "        Phone: {phone}\n",
    "        Experience Level: {experience_level}\n",
    "        Skills: {\", \".join(skills)}\n",
    "        Match Score: {score}%\n",
    "\n",
    "        Summary:\n",
    "        - This resume has been analyzed against a provided job description.\n",
    "        - The match score is calculated based on experience and skills.\n",
    "        - Consider improving skills based on job description requirements.\n",
    "\n",
    "        Thank you for using the Resume ATS Scanner.\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO resumes (name, email, phone, skills, score, experience_level, report, experience_years, skills_matched)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            name, email, phone, \",\".join(skills), score, experience_level, report,\n",
    "            experience_years, num_skills_matched\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to database: {e}\", file=sys.stderr)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.route(\"/download/<filename>\")\n",
    "def download_report(filename):\n",
    "    \"\"\"Generates and downloads the ATS match report as a multi-page PDF with wrapped text.\"\"\"\n",
    "    global job_descriptionGlobal  # Ensure we use the latest stored job description\n",
    "\n",
    "    conn = sqlite3.connect(\"resumes.db\", check_same_thread=False)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT email, phone, skills, score, experience_level FROM resumes WHERE name = ?\", (filename,))\n",
    "    row = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not row:\n",
    "        return \"Report not found!\", 404\n",
    "\n",
    "    email, phone, skills, score, experience_level = row\n",
    "    skills_list = skills.split(\",\")\n",
    "\n",
    "    # Extract job-required skills\n",
    "    job_skills = extract_skills_from_job(job_descriptionGlobal)\n",
    "    print(f\"[DEBUG] Extracted Skills from Job Description: {job_skills}\")  # ✅ Debugging Output\n",
    "\n",
    "    single_skills = match_single_digit_skills(job_descriptionGlobal, singledigit_skills)\n",
    "    print(\"Single Digit Skills !!! \", single_skills)\n",
    "    job_skills = job_skills + single_skills                             # Combine both skills into single list\n",
    "\n",
    "    # Compare skills\n",
    "    matched_skills, missing_skills = match_resume_skills(skills_list, job_skills)\n",
    "\n",
    "    # Create an in-memory PDF buffer\n",
    "    pdf_buffer = io.BytesIO()\n",
    "    pdf = canvas.Canvas(pdf_buffer, pagesize=letter)\n",
    "    pdf.setFont(\"Helvetica\", 12)\n",
    "\n",
    "    # Page settings\n",
    "    y_position = 750  # Start writing from this Y position\n",
    "    line_spacing = 20\n",
    "    margin_left = 50\n",
    "    page_height = 750  # Approximate max Y height before adding a new page\n",
    "    summary_text = [\n",
    "        \"✅ Resume analyzed against job description.\",\n",
    "        \"✅ Score based on skills and experience match.\",\n",
    "        \"✅ Consider improving skills based on job requirements.\"\n",
    "    ]\n",
    "\n",
    "    def add_new_page():\n",
    "        \"\"\"Handles adding a new page if the content exceeds the page height.\"\"\"\n",
    "        nonlocal y_position\n",
    "        pdf.showPage()\n",
    "        pdf.setFont(\"Helvetica\", 12)\n",
    "        y_position = page_height  # Reset Y position for the new page\n",
    "\n",
    "    # **1️⃣ Title Section**\n",
    "    pdf.setFont(\"Helvetica-Bold\", 18)\n",
    "    pdf.drawString(180, y_position, \"📄 Resume ATS Analysis Report\")\n",
    "    y_position -= 40\n",
    "\n",
    "    # **2️⃣ Resume Details**\n",
    "    details = [\n",
    "        (\"🔹 Filename:\", filename),\n",
    "        (\"📧 Email:\", email),\n",
    "        (\"📞 Phone:\", phone),\n",
    "        (\"🏆 Experience Level:\", experience_level),\n",
    "        (\"📊 Match Score:\", f\"{round(score)}%\")          # Round to integer score\n",
    "        # (\"📊 Match Score:\", f\"{score:.2f}%\")\n",
    "    ]\n",
    "\n",
    "    pdf.setFont(\"Helvetica\", 12)\n",
    "    for label, value in details:\n",
    "        pdf.setFont(\"Helvetica-Bold\", 12)\n",
    "        pdf.drawString(margin_left, y_position, label)\n",
    "        pdf.setFont(\"Helvetica\", 12)\n",
    "        pdf.drawString(margin_left + 120, y_position, value)\n",
    "        y_position -= line_spacing\n",
    "        if y_position <= 100:\n",
    "            add_new_page()\n",
    "\n",
    "    # **3️⃣ Skills Section**\n",
    "    pdf.setFont(\"Helvetica-Bold\", 12)\n",
    "    pdf.drawString(margin_left, y_position, \"🛠 Skills:\")\n",
    "    y_position -= line_spacing\n",
    "\n",
    "    pdf.setFont(\"Helvetica\", 12)\n",
    "    for skill in skills_list:\n",
    "        if skill in matched_skills:\n",
    "            pdf.setFont(\"Helvetica-Bold\", 12)  # ✅ Highlight matched skills in bold\n",
    "            pdf.drawString(margin_left + 20, y_position, f\"✔ {skill} (MATCH)\")\n",
    "        else:\n",
    "            pdf.setFont(\"Helvetica\", 12)\n",
    "            pdf.drawString(margin_left + 20, y_position, f\"✔ {skill}\")\n",
    "        y_position -= line_spacing\n",
    "        if y_position <= 100:\n",
    "            add_new_page()\n",
    "\n",
    "    # **4️⃣ Missing Skills Section**\n",
    "    if missing_skills:\n",
    "        pdf.setFont(\"Helvetica-Bold\", 12)\n",
    "        pdf.drawString(margin_left, y_position, \"📌 Missing Required Skills:\")\n",
    "        y_position -= line_spacing\n",
    "\n",
    "        pdf.setFont(\"Helvetica\", 12)\n",
    "        for skill in missing_skills:\n",
    "            pdf.drawString(margin_left + 20, y_position, f\"❌ {skill}\")\n",
    "            y_position -= line_spacing\n",
    "            if y_position <= 100:\n",
    "                add_new_page()\n",
    "\n",
    "    # **5️⃣ Summary Section (Auto-Wrap)**\n",
    "    pdf.setFont(\"Helvetica-Bold\", 12)\n",
    "    pdf.drawString(margin_left, y_position, \"📌 Summary:\")\n",
    "    y_position -= line_spacing\n",
    "\n",
    "    pdf.setFont(\"Helvetica\", 12)\n",
    "    for line in summary_text:\n",
    "        wrapped_lines = simpleSplit(line, \"Helvetica\", 12, 500)  # Wrap text\n",
    "        for sub_line in wrapped_lines:\n",
    "            pdf.drawString(margin_left + 20, y_position, sub_line)\n",
    "            y_position -= line_spacing\n",
    "            if y_position <= 100:\n",
    "                add_new_page()\n",
    "\n",
    "    # **6️⃣ Footer**\n",
    "    pdf.setFont(\"Helvetica-Oblique\", 10)\n",
    "    pdf.drawString(margin_left, y_position - 30, \"✨ Thank you for using the Resume ATS Scanner! ✨\")\n",
    "\n",
    "    # Save the PDF to buffer\n",
    "    pdf.showPage()\n",
    "    pdf.save()\n",
    "    pdf_buffer.seek(0)\n",
    "\n",
    "    # Send the PDF file\n",
    "    return send_file(pdf_buffer, as_attachment=True, download_name=f\"{filename}_ATS_Report.pdf\", mimetype=\"application/pdf\")\n",
    "\n",
    "\n",
    "def match_resume_to_job(resume_text, job_description):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([resume_text, job_description])\n",
    "    return round(cosine_similarity(vectors)[0, 1] * 100, 2)  # Convert to percentage\n",
    "\n",
    " # Extract Skills regardless of being case sensitive, hyphens, spaces\n",
    "def extract_skills_from_job(job_description):\n",
    "    \"\"\"Extracts required skills from job description while ignoring hyphens and spaces.\"\"\"\n",
    "    job_description_lower = job_description.lower()\n",
    "    \n",
    "    normalized_skill_map = {normalize_skill(skill): skill for skill in skill_keywords}\n",
    "    \n",
    "    job_skills = [\n",
    "        normalized_skill_map[norm_skill]\n",
    "        for norm_skill in normalized_skill_map\n",
    "        if norm_skill in normalize_skill(job_description_lower)\n",
    "    ]\n",
    "\n",
    "    return job_skills if job_skills else [\"No Skills Found\"]\n",
    "\n",
    "# Finding skills being irrespective of being case sensitive, hyphens, spaces\n",
    "def match_resume_skills(resume_skills, job_skills):\n",
    "    \"\"\"Compares resume skills with job description skills (ignoring hyphens & spaces).\"\"\"\n",
    "    \n",
    "    # Normalize both resume and job skills\n",
    "    resume_skills_map = {normalize_skill(skill): skill for skill in resume_skills}\n",
    "    job_skills_map = {normalize_skill(skill): skill for skill in job_skills}\n",
    "\n",
    "    # Find matches\n",
    "    matched_skills_lower = set(resume_skills_map.keys()) & set(job_skills_map.keys())\n",
    "\n",
    "    # Retrieve original skill names\n",
    "    matched_skills = [resume_skills_map[skill] for skill in matched_skills_lower]\n",
    "    missing_skills = [job_skills_map[skill] for skill in set(job_skills_map.keys()) - set(resume_skills_map.keys())]\n",
    "\n",
    "    return matched_skills, missing_skills\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def upload_resume():\n",
    "    \n",
    "    global job_descriptionGlobal  # 🔹 Use `global` to modify it inside this function\n",
    "    global resume_YearsExperience  # Ensure we use the latest stored resume_YearsExperience\n",
    "    \n",
    "    if request.method == \"POST\":\n",
    "        file = request.files.get(\"resume\")\n",
    "        job_description = request.form.get(\"job_description\", \"\")\n",
    "        #print('job_description in upload_resume', job_description)\n",
    "        #print('job_descriptionGlobal in upload_resume', job_descriptionGlobal)\n",
    "\n",
    "        if not file or file.filename.strip() == \"\":\n",
    "            return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "        if not job_description:\n",
    "            return jsonify({\"error\": \"No job description provided\"}), 400\n",
    "\n",
    "        # 🔹 Store job description in the global variable\n",
    "        job_descriptionGlobal = job_description  \n",
    "        #print(f\"[DEBUG] Stored Job Description: {job_descriptionGlobal}\")  # ✅ Debugging Output\n",
    "        \n",
    "        filename = secure_filename(file.filename)\n",
    "        filepath = os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)\n",
    "\n",
    "        try:\n",
    "            file.save(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file: {e}\", file=sys.stderr)\n",
    "            return jsonify({\"error\": \"Failed to save file\"}), 500\n",
    "\n",
    "        resume_text = extract_text(filepath)\n",
    "        if not resume_text:\n",
    "            return jsonify({\"error\": \"Failed to extract text from resume\"}), 500\n",
    "\n",
    "        email = extract_email(resume_text)\n",
    "        phone = extract_phone(resume_text)\n",
    "        phone = phone.replace('\\r', '').replace('\\n', '')\n",
    "        print(\"After Removing line breaks from Phone number\", phone)\n",
    "        skills = extract_skills(resume_text)\n",
    "        single_skills = match_single_digit_skills(resume_text, singledigit_skills)\n",
    "        skills = skills + single_skills                             # Combine both skills into single list of skills\n",
    "        skills = deduplicate_skills(skills)                         # Removing duplicate skills\n",
    "            \n",
    "        experience_level = categorize_experience(resume_text)\n",
    "        match_score = match_resume_to_job(resume_text, job_description)\n",
    "        print(\"Match Score based on Resume and Job Description!!!\", match_score)\n",
    "        match_score, skill_overlap = adjust_match_score(match_score, experience_level, job_description, skills)\n",
    "        print(\"BEFORE SAVING TO DB >>>>>>>>>>>\",email,phone, match_score, experience_level, skill_overlap)\n",
    "        print(\"BEFORE SAVING TO DB NUMERICAL>>\",resume_YearsExperience, skill_overlap)\n",
    "        #save_to_db(filename, email, phone, skills, round(match_score), experience_level)\n",
    "        save_to_db(filename, email, phone, skills, round(match_score), experience_level,\n",
    "        experience_years=resume_YearsExperience,\n",
    "        num_skills_matched=skill_overlap\n",
    "        )\n",
    "\n",
    "        # ✅ Instead of returning JSON, redirect to show_resume()\n",
    "        return redirect(url_for(\"show_resume\", filename=filename))\n",
    "\n",
    "    return render_template(\"upload.html\")\n",
    "\n",
    "# Extract single digit skills like \"R\", \"AI\", \"C\"\n",
    "def match_single_digit_skills(text, singledigit_skills):\n",
    "    # Construct a regex pattern that matches any of the keywords exactly as whole words\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, singledigit_skills)) + r')\\b'\n",
    "\n",
    "    # Search for the keywords in the text (case-insensitive)\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    # Remove duplicates by converting the list to a set\n",
    "    unique_matches = set(matches)\n",
    "\n",
    "    # Return the unique matches sorted\n",
    "    return sorted(unique_matches)\n",
    "\n",
    "@app.route(\"/dashboard\")\n",
    "def dashboard():\n",
    "    return render_template(\"dashboard.html\")\n",
    "\n",
    "@app.route(\"/resume/<filename>\")\n",
    "def show_resume(filename):\n",
    "    \"\"\"Displays the extracted resume details in a structured format.\"\"\"\n",
    "    filepath = os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)\n",
    "    resume_text = extract_text(filepath)\n",
    "    \n",
    "    if not resume_text:\n",
    "        return \"<h2>Error: Failed to extract resume text.</h2>\"\n",
    "\n",
    "    # Extract key information\n",
    "    email = extract_email(resume_text)\n",
    "    phone = extract_phone(resume_text)\n",
    "    skills = extract_skills(resume_text)\n",
    "    single_skills = match_single_digit_skills(resume_text, singledigit_skills)\n",
    "    skills = skills + single_skills                             # Combine both skills into single list\n",
    "    skills = deduplicate_skills(skills)                         # Removing duplicate skills\n",
    "    experience_level = categorize_experience(resume_text)\n",
    "\n",
    "    return render_template(\"resume_display.html\",\n",
    "                           filename=filename,\n",
    "                           email=email,\n",
    "                           phone=phone,\n",
    "                           skills=skills,\n",
    "                           experience_level=experience_level,\n",
    "                           resume_text=resume_text)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        app.run(host=\"127.0.0.1\", port=5000, debug=False, use_reloader=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting Flask app: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72508f-8e7d-4a38-b1f0-e05244575ff8",
   "metadata": {},
   "source": [
    "### Exporting Original Data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b59ae8-0ff4-4dfd-b02e-ee7b3b3316e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql(\"SELECT * FROM resumes\", sqlite3.connect(\"resumes.db\"))\n",
    "df.to_csv(\"resume_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11ca8f-0ef9-4f1c-968d-22d9b668f7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab63f2af-923c-4994-a008-8e0b2d521be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'SQL', 'Excel', 'R']\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_skills(skills):\n",
    "    seen = {}\n",
    "    for skill in skills:\n",
    "        key = skill.lower()\n",
    "        # Prefer capitalized skill if seen before in lowercase\n",
    "        if key not in seen or skill[0].isupper():\n",
    "            seen[key] = skill\n",
    "    return list(seen.values())\n",
    "\n",
    "\n",
    "skills = [\"Python\", \"SQL\", \"excel\", \"Excel\", \"R\", \"python\"]\n",
    "cleaned_skills = deduplicate_skills(skills)\n",
    "print(cleaned_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b0c37-edca-41e8-9d4f-adeb1dd02d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532d620-77fb-4ee8-a058-e743e995801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "\"Machine Learning Associate (Entry-Level) – Adobe\n",
    "The Opportunity\n",
    "Adobe is looking for a Machine Learning Associate (Entry-Level) who will work on AI and machine learning applications to help Adobe better understand, optimize, and improve customer experiences. This role is ideal for candidates with foundational knowledge in machine learning, predictive analytics, and data science techniques who are eager to gain hands-on experience working with real-world big-data problems.\n",
    "\n",
    "You will receive mentorship and guidance from experienced data scientists and machine learning engineers to build a strong foundation in AI-driven analytics and model development.\n",
    "\n",
    "What You’ll Do\n",
    "Assist in developing and implementing machine learning models for real-time customer insights, media optimization, and product recommendations.\n",
    "Work with structured and unstructured data to generate insights using Python, SQL, and machine learning frameworks.\n",
    "Collaborate with cross-functional teams, including data scientists, product managers, and software engineers, to improve model efficiency and interpretability.\n",
    "Apply fundamental data science techniques such as statistical modeling, feature engineering, and algorithm tuning.\n",
    "Participate in team learning sessions, code reviews, and collaborative brainstorming to enhance skills and knowledge in AI.\n",
    "What You Need to Succeed\n",
    "Bachelor’s or Master’s degree in Computer Science, Data Science, or a related field.\n",
    "Strong foundational knowledge of machine learning, statistics, and data analytics.\n",
    "Hands-on experience with Python, SQL, and machine learning frameworks (scikit-learn, TensorFlow, or PyTorch).\n",
    "Understanding of basic statistical modeling and predictive analytics.\n",
    "Ability to analyze data, apply algorithms, and interpret model results.\n",
    "Excellent communication skills and willingness to learn from experienced professionals.\n",
    "Ability to work collaboratively in a hybrid environment and contribute to team projects.\n",
    "Bonus Skills (Nice to Have, but Not Required)\n",
    "Familiarity with cloud platforms such as AWS, GCP, or Azure.\n",
    "Some exposure to big data technologies (Hadoop, Spark, Databricks).\"\n",
    "\n",
    "\"\"\"\n",
    "experience_mapping = {\n",
    "        \"Intern\": [\"Intern\"],\n",
    "        \"Junior\": [\"Entry-Level\", \"0-2 years\", \"Junior\"],\n",
    "        \"Mid-Level\": [\"Mid-Level\", \"3-7 years\"],\n",
    "        \"Senior\": [\"Senior\", \"7+ years\"]\n",
    "    }\n",
    "\n",
    "\n",
    "for mapped_exp in experience_mapping[\"Mid-Level\"]:\n",
    "    print(mapped_exp)\n",
    "    if mapped_exp.lower() in job_description.lower():\n",
    "        print(\"found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4d1a4-606d-4d66-ae9c-8bb025abc984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
